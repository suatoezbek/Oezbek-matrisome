{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get published matrisomes from the MatrisomeProject\n",
    "The Matrisome project providex excel tables that describe the matrisomes of a number of species.\n",
    "I downloaded these tables to the Subfolder MatrisomProject_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean table for further processing\n",
    "Each of the matrisomes provides different inforamtion about the proteins of the matrisome. \n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    ".tg .tg-0lax{text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\">Species</th>\n",
    "    <th class=\"tg-1wig\">Gene_Symbol</th>\n",
    "    <th class=\"tg-1wig\">ReSeq_prot_ID</th>\n",
    "    <th class=\"tg-1wig\">Uniprot_ID</th>\n",
    "    <th class=\"tg-1wig\">Ensemble_ID</th>\n",
    "    <th class=\"tg-1wig\">WormBase_ID</th>\n",
    "    <th class=\"tg-1wig\">Sequence</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">Bos taurus</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">Coturnix japonica</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">Danio rerio</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">Homo sapiens</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">Mus musculus</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">Drosophila melanogaster</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">Caenorhabditis elegans</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0lax\">Schmidtea mediterranea</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">-</td>\n",
    "    <td class=\"tg-baqh\">Yes</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I copied this information to a new excel file that only contains these columns\n",
    "However, not all the information is up to date and some of the IDs provided are deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, urllib\n",
    "from Bio import SeqRecord, Seq, SeqIO, Entrez\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "Entrez.email = # Enter your Email here\n",
    "\n",
    "# Configure logging\n",
    "log_file = 'matrisome_pipeline.log'\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO,\n",
    "                    format='%(asctime)s [%(levelname)s]: %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrival function\n",
    "def get_WormBase_sequences(WormBase_IDs):\n",
    "    protein_records = []\n",
    "    for WormBase_ID in WormBase_IDs:\n",
    "        time.sleep(0.333)\n",
    "        logging.info(f\"Retrieving sequences for WormBase ID: {WormBase_ID}\")\n",
    "        \n",
    "        gene_url = f\"http://rest.wormbase.org/rest/widget/gene/{WormBase_ID}/sequences\"\n",
    "        response = requests.get(gene_url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            gene_data = response.json()\n",
    "            gene_models = gene_data['fields']['gene_models']['data']['table']\n",
    "            \n",
    "            \n",
    "            for isoform in gene_models:\n",
    "                protein_id = isoform['protein']['id']\n",
    "                protein_label = isoform['protein']['label']\n",
    "                \n",
    "                protein_url = f\"http://rest.wormbase.org/rest/field/protein/{protein_id}/sequence\"\n",
    "                response = requests.get(protein_url)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    protein_data = response.json()\n",
    "                    sequence = protein_data['sequence']['data']['sequence']\n",
    "                    \n",
    "                    seq_record = SeqRecord.SeqRecord(Seq.Seq(sequence))\n",
    "                    seq_record.id = protein_id\n",
    "                    seq_record.name = protein_label\n",
    "                    seq_record.description = f\"Protein ID: {protein_id}, Gene Name: {gene_data['fields']['name']['data']['label']}\"\n",
    "                    \n",
    "                    protein_records.append(seq_record)\n",
    "            \n",
    "            logging.info(f\"Retrieved {len(protein_records)} protein records for WormBase ID: {WormBase_ID}\")\n",
    "            return protein_records\n",
    "        else:\n",
    "            logging.warning(f\"Error retrieving sequences for WormBase ID {WormBase_ID}. Status code: {response.status_code}\")\n",
    "            return []\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "def get_FlyBase_sequences(gene_ids):\n",
    "    sequences = []\n",
    "    for gene_id in gene_ids:\n",
    "        time.sleep(0.333)\n",
    "        logging.info(f\"Retrieving sequences for FlyBase ID: {gene_id}\")\n",
    "        \n",
    "        url = f\"http://api.flybase.org/api/v1.0/sequence/id/{gene_id}/FBpp\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            result = data['resultset'].get('result', [])\n",
    "            if result:\n",
    "                \n",
    "                for entry in result:\n",
    "                    seq_record = SeqRecord.SeqRecord(Seq.Seq(entry['sequence']), id=entry['id'], description=entry['description'])\n",
    "                    sequences.append(seq_record)\n",
    "                logging.info(f\"Retrieved {len(sequences)} sequences for FlyBase ID: {gene_id}\")\n",
    "                return sequences\n",
    "            else:\n",
    "                logging.warning(f\"No sequences found for the given FlyBase ID: {gene_id}\")\n",
    "                return []\n",
    "        else:\n",
    "            logging.warning(f\"Error retrieving data for FlyBase ID {gene_id}. Status code: {response.status_code}\")\n",
    "            return []\n",
    "    \n",
    "#---------------------------------------------------------------------------------------------\n",
    "def retrieve_RefSeq_sequences(RefSeq_IDs):\n",
    "    logging.info(f\"Retrieving RefSeq sequences for IDs: {RefSeq_IDs}\")\n",
    "    RefSeq_IDs = [id_.rstrip('.') for id_ in RefSeq_IDs]  # remove trailing \".\"\n",
    "    sequences = []\n",
    "\n",
    "    try:\n",
    "        handle = Entrez.efetch(db=\"protein\", id=\",\".join(RefSeq_IDs), rettype=\"fasta\", retmode=\"text\")\n",
    "        records = SeqIO.parse(handle, \"fasta\")\n",
    "        sequences = list(records)\n",
    "        handle.close()\n",
    "        logging.info(f\"Retrieved {len(sequences)} sequences\")\n",
    "    except urllib.error.HTTPError as e:\n",
    "        logging.error(f\"HTTP Error occurred: {e}\")\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "\n",
    "    return sequences\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "def retrieve_uniprot_sequences(uniprot_IDs):\n",
    "    time.sleep(0.333)\n",
    "    logging.info(f\"Retrieving sequences for Uniprot: {uniprot_IDs}\")\n",
    "    records = []\n",
    "    \n",
    "    for uniprot_id in uniprot_IDs:\n",
    "        if len(uniprot_id) < 4:\n",
    "            continue\n",
    "        current_url = f\"http://www.uniprot.org/uniprot/{uniprot_id}.fasta\"\n",
    "        response = requests.get(current_url)\n",
    "        cData = response.text\n",
    "\n",
    "        if not cData:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            pSeq = SeqIO.read(StringIO(cData), 'fasta')\n",
    "            records.append(pSeq)\n",
    "            logging.info(f\"Retrieved sequence for UniProt ID: {uniprot_id}\")\n",
    "        except ValueError as e:\n",
    "            logging.warning(f\"Error reading sequence for UniProt ID {uniprot_id}: {e}\")\n",
    "\n",
    "    return records\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "def retrieve_ensembl_sequence(ensemble_ids):\n",
    "    records = []\n",
    "    for ensemble_id in ensemble_ids:\n",
    "        time.sleep(0.333)\n",
    "        logging.info(f\"Retrieving sequences for Ensembl: {ensemble_id}\")\n",
    "        server = \"https://rest.ensembl.org\"\n",
    "        ext = f\"/sequence/id/{ensemble_id}?type=protein;multiple_sequences=TRUE\"\n",
    "        r = requests.get(server+ext,headers={\"Content-Type\": \"text/x-fasta\"})\n",
    "        cData = r.text\n",
    "        if not cData:\n",
    "            continue\n",
    "\n",
    "        # Parse the FASTA data\n",
    "        try:\n",
    "            sequence = SeqIO.parse(StringIO(cData), 'fasta')\n",
    "            records.extend(sequence)\n",
    "            logging.info(f\"Retrieved sequence for UniProt ID: {ensemble_id}\")\n",
    "        except ValueError as e:\n",
    "            logging.warning(f\"Error reading sequence for UniProt ID {ensemble_id}: {e}\")\n",
    "    return records\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "def find_gene_symbol_sequences(gene_symbol, organism):\n",
    "    time.sleep(0.333)\n",
    "    logging.info(f\"Retrieving sequences for : {gene_symbol} in {organism}\")\n",
    "    try:\n",
    "        query = f'{gene_symbol} AND {organism} [ORGN]'\n",
    "        handle = Entrez.esearch(db=\"protein\", term=query)\n",
    "        record = Entrez.read(handle)\n",
    "        handle.close()\n",
    "\n",
    "        if record['IdList']:\n",
    "            handle = Entrez.efetch(db=\"protein\", id=\",\".join(record['IdList']), rettype=\"fasta\", retmode=\"text\")\n",
    "            records = list(SeqIO.parse(handle, \"fasta\"))\n",
    "            handle.close()\n",
    "            logging.info(f\"Retrieved sequences for gene symbol: {gene_symbol}, organism: {organism}\")\n",
    "            return records\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Error retrieving sequences for gene symbol: {gene_symbol}, organism: {organism}. Error: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "def create_fasta_records(sequence, gene_symbol):\n",
    "    records = []\n",
    "    record = SeqRecord.SeqRecord(Seq.Seq(sequence), id=gene_symbol, description='', name=gene_symbol)\n",
    "    record.annotations[\"molecule_type\"] = \"protein\"\n",
    "    records.append(record)\n",
    "    \n",
    "    # Log the creation of fasta record\n",
    "    logging.info(f\"Created fasta record for gene symbol: {gene_symbol}\")\n",
    "    \n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through all species and genes and look up all possible seq records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the tables of genes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define where the input files are\n",
    "input_folder = Path(r\"E:\\mesoglea_protein_pipeline\\published_input\")\n",
    "matrisome_folder = input_folder / 'modified_tables'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xlsx_files_and_read(folder_path):\n",
    "    data_dict = {}\n",
    "\n",
    "    for file_path in Path(folder_path).rglob('*.xlsx'):\n",
    "        species = file_path.stem\n",
    "        df = pd.read_excel(file_path)\n",
    "        df = df.set_index(\"gene_symbol\")\n",
    "        df[\"deprecated\"] = False\n",
    "        data_dict[species] = df\n",
    "        \n",
    "        # Log the loading of a DataFrame\n",
    "        logging.info(f\"Loaded DataFrame for species: {species}\")\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "matrisome_dict = get_xlsx_files_and_read(matrisome_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_sequences(row, species, index, gene_seqs_folder):\n",
    "    sequences = []\n",
    "\n",
    "    if Path.is_file(gene_seqs_folder / f\"{index}.fasta\"):\n",
    "        sequences = list(SeqIO.parse(gene_seqs_folder / f\"{index}.fasta\",\"fasta\"))\n",
    "        if len(sequences)>0:\n",
    "            return sequences\n",
    "\n",
    "    if 'sequence' in row and row[\"sequence\"] and isinstance(row['sequence'], str):\n",
    "        sequences.extend(create_fasta_records(row['sequence'], index))\n",
    "        logging.info(f\"Created fasta records for gene symbol: {index}\")\n",
    "\n",
    "    if 'uniprot_ID' in row and isinstance(row['uniprot_ID'], str) and len(row['uniprot_ID'])>3 :\n",
    "        uniprot_ids = re.split(r'[:;]', row['uniprot_ID'])\n",
    "        sequences.extend(retrieve_uniprot_sequences(uniprot_ids))\n",
    "        logging.info(f\"Retrieved UniProt sequences for gene symbol: {index}\")\n",
    "\n",
    "    if 'RefSeq_ID' in row and len(row['RefSeq_ID'])>3 and isinstance(row['RefSeq_ID'], str):\n",
    "        refseq_ids = re.split(r'[:;]', row['RefSeq_ID'])\n",
    "        sequences.extend(retrieve_RefSeq_sequences(refseq_ids))\n",
    "        logging.info(f\"Retrieved RefSeq sequences for gene symbol: {index}\")\n",
    "\n",
    "    if 'WormBase_ID' in row and row['WormBase_ID']and isinstance(row['WormBase_ID'], str):\n",
    "        refseq_ids = re.split(r'[:;]', row['WormBase_ID'])\n",
    "        sequences.extend(get_WormBase_sequences(refseq_ids))\n",
    "        logging.info(f\"Retrieved WormBase sequences for gene symbol: {index}\")\n",
    "\n",
    "    if 'FlyBaseID' in row and row['FlyBaseID'] and isinstance(row['FlyBaseID'], str):\n",
    "        refseq_ids = re.split(r'[:;]', row['FlyBaseID'])\n",
    "        sequences.extend(get_FlyBase_sequences(refseq_ids))\n",
    "        logging.info(f\"Retrieved FlyBase sequences for gene symbol: {index}\")\n",
    "\n",
    "    if 'ensembl_ID' in row and row['ensembl_ID']and isinstance(row['ensembl_ID'], str):\n",
    "        refseq_ids = re.split(r'[:;]', row['ensembl_ID'])\n",
    "        sequences.extend(retrieve_ensembl_sequence(refseq_ids))\n",
    "        logging.info(f\"Retrieved Ensembl sequences for gene symbol: {index}\")\n",
    "\n",
    "    if len(sequences) == 0 and index:\n",
    "        sequences= find_gene_symbol_sequences(index, species)\n",
    "        logging.info(f\"No sequences found for gene symbol: {index}\")\n",
    "\n",
    "    if sequences:\n",
    "        logging.info(f\"Found {len(sequences)} sequences.\")\n",
    "    else:\n",
    "        logging.info(f\"Found 0 sequences.\")\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: Chordata_Vertebrata_Bos_taurus\n",
      "\t expected number of sequences: 1087\n",
      "Found missing data for Chordata_Vertebrata_Bos_taurus. Continuing with 1 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: Chordata_Vertebrata_Coturnix_japonica\n",
      "\t expected number of sequences: 757\n",
      "Found missing data for Chordata_Vertebrata_Coturnix_japonica. Continuing with 69 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:56<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: Chordata_Vertebrata_Danio_rerio\n",
      "\t expected number of sequences: 1015\n",
      "Found missing data for Chordata_Vertebrata_Danio_rerio. Continuing with 42 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:50<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: Chordata_Vertebrata_Homo_sapiens\n",
      "\t expected number of sequences: 1027\n",
      "Run normally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1027/1027 [00:09<00:00, 105.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFound: 1027 Sequences\n",
      "Working on: Chordata_Vertebrata_Mus_musculus\n",
      "\t expected number of sequences: 1110\n",
      "Found missing data for Chordata_Vertebrata_Mus_musculus. Continuing with 1 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: Insecta_Diptera_Drosophila_melanogaster\n",
      "\t expected number of sequences: 641\n",
      "Run normally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 641/641 [00:19<00:00, 32.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFound: 641 Sequences\n",
      "Working on: Nematoda_Chromadorea_Caenorhabditis_elegans\n",
      "\t expected number of sequences: 719\n",
      "Found missing data for Nematoda_Chromadorea_Caenorhabditis_elegans. Continuing with 2 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: Platyhelminthes_Tricladida_Schmidtea_mediterranea\n",
      "\t expected number of sequences: 256\n",
      "Run normally.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:02<00:00, 111.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFound: 256 Sequences\n"
     ]
    }
   ],
   "source": [
    "with open('logfile.log', 'w'):\n",
    "    pass\n",
    "# Add log messages at relevant points in your code\n",
    "logging.info(\"Starting matrisome processing...\")\n",
    "\n",
    "# Iterate through each species and its corresponding DataFrame\n",
    "for species, main_df in matrisome_dict.items():\n",
    "    main_df = main_df.dropna(axis=1)\n",
    "    update= False\n",
    "    print(f\"Working on: {species}\")\n",
    "    print(f\"\\t expected number of sequences: {main_df.shape[0]}\")\n",
    "    logging.info(f\"Working on: {species}\")\n",
    "    logging.info(f\"\\t expected number of sequences: {main_df.shape[0]}\")\n",
    "\n",
    "    # Check if a _missing.csv file exists for the species\n",
    "    missing_path = matrisome_folder / \"missing\" / f\"{species}_missing.csv\"\n",
    "    if missing_path.is_file():\n",
    "        # If the file exists, read it as a DataFrame\n",
    "        df = pd.read_csv(missing_path)\n",
    "        df = df.set_index(\"gene_symbol\")\n",
    "        print(f\"Found missing data for {species}. Continuing with {df.shape[0]} rows.\")\n",
    "        logging.info(f\"Found missing data for {species}. Continuing with {df.shape[0]} rows.\")\n",
    "        update = True\n",
    "    else:\n",
    "        df = main_df\n",
    "        print(\"Run normally.\")\n",
    "\n",
    "    df['deprecated'] = df['deprecated'].astype('object')    \n",
    "    best_guess_matrisome = []  # Initialize the list to hold the longest sequences\n",
    "    missing = pd.DataFrame(columns=df.columns)  # Initialize the DataFrame for missing rows\n",
    "    missing_ids = list()\n",
    "    gene_seqs_folder = matrisome_folder / \"gene_seqs\" / species\n",
    "    gene_seqs_folder.mkdir(parents=True, exist_ok=True)    \n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        tax = species.split(\"_\")\n",
    "        species_name = \" \".join([tax[-2], tax[-1]])\n",
    "        sequences = get_gene_sequences(row, species_name,index,gene_seqs_folder)\n",
    "\n",
    "        if sequences:\n",
    "            # Find the longest sequence\n",
    "            longest_sequence = max(sequences, key=lambda x: len(x.seq))\n",
    "            best_guess_matrisome.append(longest_sequence)\n",
    "\n",
    "            # Create a subfolder \"gene_seqs\"\n",
    "\n",
    "\n",
    "            # Create a fasta file for the gene\n",
    "            clean_id = str(index).replace(\"/\",\"_\").replace(\"\\\\\",\"_\")\n",
    "            gene_fasta_path = gene_seqs_folder / f\"{clean_id}.fasta\"\n",
    "            main_df.loc[index,\"potential SeqIDs\"] = \";\".join([seq.id for seq in sequences])\n",
    "            main_df.loc[index,\"longest Sequence\"] = str(longest_sequence.seq)\n",
    "            SeqIO.write(sequences, gene_fasta_path, \"fasta\")\n",
    "\n",
    "            # Remove the deprecated tag from the main df\n",
    "            main_df.loc[index,\"deprecated\"] = \"\"\n",
    "\n",
    "        else:\n",
    "            # If no sequences found, add the row to the missing DataFrame\n",
    "            missing.loc[index] = row\n",
    "            missing_ids.append(index)\n",
    "\n",
    "    # Create a fasta file for the best guess matrisome\n",
    "    best_guess_path = matrisome_folder/\"retrived_sequences\"\n",
    "    best_guess_path.mkdir(parents=True, exist_ok=True)\n",
    "    if best_guess_matrisome:\n",
    "        best_guess_fasta_path = best_guess_path / f\"{species}.fasta\"\n",
    "        if update and Path.is_file(best_guess_fasta_path):\n",
    "            print(f\"Adding {len(best_guess_matrisome)}\")\n",
    "            exsisting_seqs = list(SeqIO.parse(best_guess_fasta_path, \"fasta\"))\n",
    "            best_guess_matrisome = best_guess_matrisome + exsisting_seqs\n",
    "            assert len(best_guess_matrisome) > len(exsisting_seqs)\n",
    "            missing_path.unlink()# delete the old tabel of missing sequences\n",
    "        SeqIO.write(best_guess_matrisome, best_guess_fasta_path, \"fasta\")\n",
    "        logging.info(f\"\\tFound: {len(best_guess_matrisome)} Sequences\")\n",
    "        print(f\"\\tFound: {len(best_guess_matrisome)} Sequences\")\n",
    "    \n",
    "    # Save the \"missing\" DataFrame as a CSV file\n",
    "    missing_path = matrisome_folder/\"missing\"\n",
    "    missing_path.mkdir(parents=True, exist_ok=True)\n",
    "    if missing.shape[0]:\n",
    "        missing_csv_path = missing_path/ f\"{species}_missing.csv\"\n",
    "        missing['gene_symbol'] = missing_ids\n",
    "        missing.to_csv(missing_csv_path, index=False)\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for species,df in matrisome_dict.items():\n",
    "    df.to_csv(f\"filled_{species}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deprecated</th>\n",
       "      <th>potential SeqIDs</th>\n",
       "      <th>longest Sequence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COL10A1</th>\n",
       "      <td></td>\n",
       "      <td>sp|P23206.1|COAA1_BOVIN;NP_777059.1;DAA26300.1...</td>\n",
       "      <td>MLPQTALLLLMSLNLVHGVFYTERYQTPTGIKGPPSNTKTQFFIPY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COL11A1</th>\n",
       "      <td></td>\n",
       "      <td>XP_059737868.1;XP_059737865.1;sp|Q28083.1|COBA...</td>\n",
       "      <td>MERWSSRWKTKRWLWDFTITTLALTFLFQAREVRGADPVDVLKALD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COL11A2</th>\n",
       "      <td></td>\n",
       "      <td>XP_059736316.1;sp|Q32S24.1|COBA2_BOVIN;NP_0010...</td>\n",
       "      <td>MERCSRCHHLLLLVLLLLWLSAAPAWAGTAPVDVLRALRFPALPDG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COL12A1</th>\n",
       "      <td></td>\n",
       "      <td>XP_059745578.1;XP_059745577.1;XP_059745576.1;s...</td>\n",
       "      <td>MRIRLPPALAALGAALLLSSIEAEVEPPSDLNFKIIDENTVHMSWA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COL13A1</th>\n",
       "      <td></td>\n",
       "      <td>XP_059738581.1;XP_059738580.1;XP_059738579.1;X...</td>\n",
       "      <td>MVAERSRKATAAGARGPAELDAPGTVALAVAPAERCARLPSPGSCG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td></td>\n",
       "      <td>pdb|8GRR|L;pdb|6NO7|D;pdb|6NHG|G;pdb|6NKN|N;pd...</td>\n",
       "      <td>MSSQVEHPAGGYKKLFETVEELSSPLTAHVTGRIPLWLTGSLLRCG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td></td>\n",
       "      <td>pdb|6NHG|G;pdb|6NKN|N;pdb|6NMP|N;pdb|6NMF|N;pd...</td>\n",
       "      <td>MNPSASFLAGRQNIGSEVEISTIEKQRKELQLLIGELKDRDRELND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td></td>\n",
       "      <td>pdb|6MRQ|A;pdb|6NHG|H;pdb|6NKN|N;pdb|6NMP|N;pd...</td>\n",
       "      <td>MSSGLWSQEKVTSPYWEERIFYLLLQECSVTDKQTQKLLKVPKGSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td></td>\n",
       "      <td>pdb|6NHG|H;pdb|6NKN|N;pdb|6NMP|N;pdb|6NMF|N;pd...</td>\n",
       "      <td>MDIREEKHINTALQVSSFRTALRGFERLVEHVAAQKRDERAGVFAP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td></td>\n",
       "      <td>pdb|6NHG|H;pdb|6NKN|N;pdb|6NMP|N;pdb|6NMF|N;pd...</td>\n",
       "      <td>MSSQVEHPAGGYKKLFETVEELSSPLTAHVTGRIPLWLTGSLLRCG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1087 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            deprecated                                   potential SeqIDs  \\\n",
       "gene_symbol                                                                 \n",
       "COL10A1                 sp|P23206.1|COAA1_BOVIN;NP_777059.1;DAA26300.1...   \n",
       "COL11A1                 XP_059737868.1;XP_059737865.1;sp|Q28083.1|COBA...   \n",
       "COL11A2                 XP_059736316.1;sp|Q32S24.1|COBA2_BOVIN;NP_0010...   \n",
       "COL12A1                 XP_059745578.1;XP_059745577.1;XP_059745576.1;s...   \n",
       "COL13A1                 XP_059738581.1;XP_059738580.1;XP_059738579.1;X...   \n",
       "...                ...                                                ...   \n",
       "61                      pdb|8GRR|L;pdb|6NO7|D;pdb|6NHG|G;pdb|6NKN|N;pd...   \n",
       "62                      pdb|6NHG|G;pdb|6NKN|N;pdb|6NMP|N;pdb|6NMF|N;pd...   \n",
       "63                      pdb|6MRQ|A;pdb|6NHG|H;pdb|6NKN|N;pdb|6NMP|N;pd...   \n",
       "64                      pdb|6NHG|H;pdb|6NKN|N;pdb|6NMP|N;pdb|6NMF|N;pd...   \n",
       "65                      pdb|6NHG|H;pdb|6NKN|N;pdb|6NMP|N;pdb|6NMF|N;pd...   \n",
       "\n",
       "                                              longest Sequence  \n",
       "gene_symbol                                                     \n",
       "COL10A1      MLPQTALLLLMSLNLVHGVFYTERYQTPTGIKGPPSNTKTQFFIPY...  \n",
       "COL11A1      MERWSSRWKTKRWLWDFTITTLALTFLFQAREVRGADPVDVLKALD...  \n",
       "COL11A2      MERCSRCHHLLLLVLLLLWLSAAPAWAGTAPVDVLRALRFPALPDG...  \n",
       "COL12A1      MRIRLPPALAALGAALLLSSIEAEVEPPSDLNFKIIDENTVHMSWA...  \n",
       "COL13A1      MVAERSRKATAAGARGPAELDAPGTVALAVAPAERCARLPSPGSCG...  \n",
       "...                                                        ...  \n",
       "61           MSSQVEHPAGGYKKLFETVEELSSPLTAHVTGRIPLWLTGSLLRCG...  \n",
       "62           MNPSASFLAGRQNIGSEVEISTIEKQRKELQLLIGELKDRDRELND...  \n",
       "63           MSSGLWSQEKVTSPYWEERIFYLLLQECSVTDKQTQKLLKVPKGSI...  \n",
       "64           MDIREEKHINTALQVSSFRTALRGFERLVEHVAAQKRDERAGVFAP...  \n",
       "65           MSSQVEHPAGGYKKLFETVEELSSPLTAHVTGRIPLWLTGSLLRCG...  \n",
       "\n",
       "[1087 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrisome_dict[\"Chordata_Vertebrata_Bos_taurus\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
